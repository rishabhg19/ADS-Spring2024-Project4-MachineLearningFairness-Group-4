{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lPkw2MjSwrDI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.metrics import mutual_info_score\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data by encoding categorical variables and removing null values."
      ],
      "metadata": {
        "id": "fIYPDkH5wzIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')\n",
        "df['score_text'] = df['score_text'].replace({'High': 2, 'Medium': 1, 'Low': 0})\n",
        "df['score_text'] = df['score_text'].fillna(0)\n",
        "df['v_score_text'] = df['v_score_text'].replace({'High': 2, 'Medium': 1, 'Low': 0})\n",
        "df['v_score_text'] = df['v_score_text'].fillna(0)\n",
        "df = df[df['race'].isin(['Caucasian', 'African-American'])]\n",
        "df['race'] = df['race'].replace({'Caucasian': 1, 'African-American': 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4y8ehHdwzmZ",
        "outputId": "7f763f52-2473-480f-c798-5add5c3bd868"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-625051a31eaa>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['race'] = df['race'].replace({'Caucasian': 1, 'African-American': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Make a Logistic Regression model that predicts two_year_recidivism without any prejudice remover. Notice that without any prejudice removal, the model predicts recidivism more accurately for Caucasians compared to African Americans."
      ],
      "metadata": {
        "id": "i2E7KzsYw4QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['id', 'age', 'juv_fel_count', 'juv_misd_count', 'is_recid', 'decile_score','juv_other_count', 'priors_count', 'v_score_text', 'is_violent_recid', 'race']].copy()\n",
        "X = X.fillna(0)\n",
        "Y = df['two_year_recid'].copy()\n",
        "unfair_model = LogisticRegression(max_iter=1000)\n",
        "unfair_model.fit(X, Y)\n",
        "\n",
        "priv = X[X['race'] == 1]\n",
        "unpriv = X[X['race'] == 0]\n",
        "\n",
        "priv_pred = unfair_model.predict(priv)\n",
        "unpriv_pred = unfair_model.predict(unpriv)\n",
        "\n",
        "accuracy_priv = accuracy_score(Y[X['race'] == 1], priv_pred)\n",
        "accuracy_unpriv = accuracy_score(Y[X['race'] == 0], unpriv_pred)\n",
        "\n",
        "print(\"Accuracy for privileged group (race == 1):\", accuracy_priv)\n",
        "print(\"Accuracy for unprivileged group (race == 0):\", accuracy_unpriv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G1G_AMRw1nG",
        "outputId": "c4454c00-0dfd-49a7-ee68-2fb5508f6112"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for privileged group (race == 1): 0.7224938875305623\n",
            "Accuracy for unprivileged group (race == 0): 0.7126623376623377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without the `is_recid` feature, the accuracies from the Logistric Regression model for the privileged and unprivileged groups both decrease significantly, while the difference between the two accuracies remains almost the same."
      ],
      "metadata": {
        "id": "JOFTNOYt3BCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['id', 'age', 'juv_fel_count', 'juv_misd_count', 'decile_score','juv_other_count', 'priors_count', 'v_score_text', 'is_violent_recid', 'race']].copy()\n",
        "X = X.fillna(0)\n",
        "Y = df['two_year_recid'].copy()\n",
        "unfair_model = LogisticRegression(max_iter=1000)\n",
        "unfair_model.fit(X, Y)\n",
        "priv = X[X['race'] == 1]\n",
        "unpriv = X[X['race'] == 0]\n",
        "\n",
        "priv_pred = unfair_model.predict(priv)\n",
        "unpriv_pred = unfair_model.predict(unpriv)\n",
        "\n",
        "accuracy_priv = accuracy_score(Y[X['race'] == 1], priv_pred)\n",
        "accuracy_unpriv = accuracy_score(Y[X['race'] == 0], unpriv_pred)\n",
        "\n",
        "print(\"Accuracy for privileged group (race == 1):\", accuracy_priv)\n",
        "print(\"Accuracy for unprivileged group (race == 0):\", accuracy_unpriv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6WdAHIf28ni",
        "outputId": "6160665f-7961-46b0-aba6-60a4c6c74811"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "6       1\n",
            "8       0\n",
            "       ..\n",
            "7207    1\n",
            "7208    0\n",
            "7209    0\n",
            "7210    0\n",
            "7212    0\n",
            "Name: two_year_recid, Length: 6150, dtype: int64\n",
            "Accuracy for privileged group (race == 1): 0.7224938875305623\n",
            "Accuracy for unprivileged group (race == 0): 0.7126623376623377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Store the class Y, the non-sensitive features X, and the sensitive feature S separately."
      ],
      "metadata": {
        "id": "F0sjd5aUw7v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_sensitive_features = ['id', 'age', 'juv_fel_count', 'is_recid','juv_other_count', 'priors_count', 'v_score_text', 'is_violent_recid']\n",
        "X = df[non_sensitive_features].copy()\n",
        "Y = df['two_year_recid'].copy()\n",
        "S = df['race'].copy()\n",
        "print(X)\n",
        "print(Y)\n",
        "print(S)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXhAQxpJw9JC",
        "outputId": "3ce2142d-93ea-429d-c87f-fb509239d200"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  age  juv_fel_count  is_recid  juv_other_count  priors_count  \\\n",
            "1         3   34              0         1                0             0   \n",
            "2         4   24              0         1                1             4   \n",
            "3         5   23              0         0                0             1   \n",
            "6         8   41              0         1                0            14   \n",
            "8        10   39              0         0                0             0   \n",
            "...     ...  ...            ...       ...              ...           ...   \n",
            "7207  10994   30              0         1                0             0   \n",
            "7208  10995   20              0         0                0             0   \n",
            "7209  10996   23              0         0                0             0   \n",
            "7210  10997   23              0         0                0             0   \n",
            "7212  11000   33              0         0                0             3   \n",
            "\n",
            "      v_score_text  is_violent_recid  \n",
            "1                0                 1  \n",
            "2                0                 0  \n",
            "3                1                 0  \n",
            "6                0                 0  \n",
            "8                0                 0  \n",
            "...            ...               ...  \n",
            "7207             0                 0  \n",
            "7208             2                 0  \n",
            "7209             1                 0  \n",
            "7210             1                 0  \n",
            "7212             0                 0  \n",
            "\n",
            "[6150 rows x 8 columns]\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "6       1\n",
            "8       0\n",
            "       ..\n",
            "7207    1\n",
            "7208    0\n",
            "7209    0\n",
            "7210    0\n",
            "7212    0\n",
            "Name: two_year_recid, Length: 6150, dtype: int64\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "6       1\n",
            "8       1\n",
            "       ..\n",
            "7207    0\n",
            "7208    0\n",
            "7209    0\n",
            "7210    0\n",
            "7212    0\n",
            "Name: race, Length: 6150, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PRLOSS(unpriv, priv, learning_rate):\n",
        "    unpriv_float = tf.cast(unpriv, dtype=tf.float32)\n",
        "    priv_float = tf.cast(priv, dtype=tf.float32)\n",
        "\n",
        "    n_unpriv = tf.cast(tf.shape(unpriv_float)[0], dtype=tf.float32)\n",
        "    n_priv = tf.cast(tf.shape(priv_float)[0], dtype=tf.float32)\n",
        "\n",
        "    n_unpriv = tf.maximum(n_unpriv, 1.0)\n",
        "    n_priv = tf.maximum(n_priv, 1.0)\n",
        "\n",
        "    Dxisi = tf.stack([n_priv, n_unpriv], axis=0)\n",
        "\n",
        "    y_pred_priv = tf.reduce_sum(priv_float)\n",
        "    y_pred_unpriv = tf.reduce_sum(unpriv_float)\n",
        "\n",
        "    P_ys_stacked = tf.stack([y_pred_priv, y_pred_unpriv], axis=0)\n",
        "    P_ys = P_ys_stacked / Dxisi\n",
        "\n",
        "    P = tf.concat([unpriv_float, priv_float], axis=0)\n",
        "\n",
        "    P_sum = tf.reduce_sum(P)\n",
        "    total_samples = tf.cast(tf.size(unpriv_float) + tf.size(priv_float), dtype=tf.float32)\n",
        "    P_y = P_sum / total_samples\n",
        "\n",
        "    P_y = tf.maximum(P_y, 1e-12)\n",
        "\n",
        "    log_P_ys_1 = tf.math.log(P_ys[1])\n",
        "    log_P_y = tf.math.log(P_y)\n",
        "    P_s1y1 = log_P_ys_1 - log_P_y\n",
        "\n",
        "    log_1_minus_P_ys_1 = tf.math.log(1 - P_ys[1])\n",
        "    log_1_minus_P_y = tf.math.log(1 - P_y)\n",
        "    P_s1y0 = log_1_minus_P_ys_1 - log_1_minus_P_y\n",
        "\n",
        "    log_P_ys_0 = tf.math.log(P_ys[0])\n",
        "    log_P_y = tf.math.log(P_y)\n",
        "    P_s0y1 = log_P_ys_0 - log_P_y\n",
        "\n",
        "    log_1_minus_P_ys_0 = tf.math.log(1 - P_ys[0])\n",
        "    log_1_minus_P_y = tf.math.log(1 - P_y)\n",
        "    P_s0y0 = log_1_minus_P_ys_0 - log_1_minus_P_y\n",
        "\n",
        "    P_s1y1 = tf.reshape(P_s1y1, [-1])\n",
        "    P_s1y0 = tf.reshape(P_s1y0, [-1])\n",
        "    P_s0y1 = tf.reshape(P_s0y1, [-1])\n",
        "    P_s0y0 = tf.reshape(P_s0y0, [-1])\n",
        "\n",
        "    PI_s1y1 = unpriv_float * P_s1y1\n",
        "    PI_s1y0 = (1 - unpriv_float) * P_s1y0\n",
        "    PI_s0y1 = priv_float * P_s0y1\n",
        "    PI_s0y0 = (1 - priv_float) * P_s0y0\n",
        "\n",
        "    PI = tf.reduce_sum(PI_s1y1) + tf.reduce_sum(PI_s1y0) + tf.reduce_sum(PI_s0y1) + tf.reduce_sum(PI_s0y0)\n",
        "\n",
        "    return learning_rate * PI\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n",
        "\n",
        "# In Rishabh's code the loss and val_loss were NaN during training,\n",
        "# so I checked for NaN or infinite values in the data (to ensure data integrity)\n",
        "print(\"NaN values in X_train:\", np.any(np.isnan(X_train)))\n",
        "print(\"NaN values in X_test:\", np.any(np.isnan(X_test)))\n",
        "print(\"NaN values in Y_train:\", np.any(np.isnan(Y_train)))\n",
        "print(\"NaN values in Y_test:\", np.any(np.isnan(Y_test)))\n",
        "\n",
        "# Normalize the input features -> zero mean and unit variance\n",
        "X_train_normalized = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
        "X_test_normalized = (X_test - X_test.mean(axis=0)) / X_test.std(axis=0)\n",
        "\n",
        "\n",
        "def prediction_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(input_shape,))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the model with the custom loss function\n",
        "model = prediction_model(X_train.shape[1])\n",
        "model.compile(optimizer='adam', loss=lambda y_true, y_pred: PRLOSS(y_true, y_pred, learning_rate=0.1), metrics = ['accuracy'])\n",
        "\n",
        "# Train the model with normalized data\n",
        "model.fit(X_train_normalized, Y_train, epochs=10, batch_size=32, validation_data=(X_test_normalized[:50], Y_test[:50]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWWKa2YnxOkR",
        "outputId": "3e17f5e1-8d9e-41e0-927d-366921b90c5b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in X_train: False\n",
            "NaN values in X_test: False\n",
            "NaN values in Y_train: False\n",
            "NaN values in Y_test: False\n",
            "Epoch 1/10\n",
            "173/173 [==============================] - 2s 3ms/step - loss: 0.0169 - accuracy: 0.7619 - val_loss: 0.0043 - val_accuracy: 0.7600\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.7807 - val_loss: 0.0038 - val_accuracy: 0.7600\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.8013 - val_loss: 0.0031 - val_accuracy: 0.7800\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.8287 - val_loss: 0.0024 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.8497 - val_loss: 0.0019 - val_accuracy: 0.8400\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.8753 - val_loss: 0.0014 - val_accuracy: 0.8800\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9010 - val_loss: 9.9942e-04 - val_accuracy: 0.9400\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9165 - val_loss: 8.5214e-04 - val_accuracy: 0.9400\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9283 - val_loss: 7.0566e-04 - val_accuracy: 0.9400\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9395 - val_loss: 6.1663e-04 - val_accuracy: 0.9400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788823220d90>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(X_test_normalized, Y_test)\n",
        "print(evaluation)\n",
        "privX_train, privX_test, privY_train, privY_test = train_test_split(priv,priv_pred, test_size=0.5, random_state=42)\n",
        "unprivX_train, unprivX_test, unprivY_train, unprivY_test = train_test_split(unpriv,unpriv_pred, test_size=0.5, random_state=42)\n",
        "privX_test_normalized = (privX_test - privX_test.mean(axis=0)) / privX_test.std(axis=0)\n",
        "unprivX_test_normalized = (unprivX_test - unprivX_test.mean(axis=0)) / unprivX_test.std(axis=0)\n",
        "# print(\"NaN values in Y_train:\", np.any(np.isnan(privX_test)))\n",
        "# print(\"NaN values in Y_test:\", np.any(np.isnan(privY_test)))\n",
        "priv_loss, priv_accuracy = model.evaluate(privX_test, privY_test)\n",
        "print(\"Privileged Data Loss:\", priv_loss)\n",
        "print(\"Privileged Data Accuracy:\", priv_accuracy)\n",
        "\n",
        "unpriv_loss, unpriv_accuracy = model.evaluate(unprivX_test, unprivY_test)\n",
        "print(\"Unprivileged Data Loss:\", unpriv_loss)\n",
        "print(\"Unprivileged Data Accuracy:\", unpriv_accuracy)"
      ],
      "metadata": {
        "id": "CNClpQT5zizR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "52c9c848-fc66-4338-c8c5-6bf1fe424242"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9415\n",
            "[0.009600960649549961, 0.9414634108543396]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 8), found shape=(None, 10)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-096d0f570871>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(\"NaN values in Y_train:\", np.any(np.isnan(privX_test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(\"NaN values in Y_test:\", np.any(np.isnan(privY_test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpriv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprivX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Privileged Data Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Privileged Data Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriv_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 8), found shape=(None, 10)\n"
          ]
        }
      ]
    }
  ]
}